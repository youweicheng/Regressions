{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Simple Linear Regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np \nfrom sklearn.linear_model import LinearRegression",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1)) # Â∞áxËΩâÁÇ∫‰∫åÁ∂≠Â∫¶, one column and as many rows as necessay\ny = np.array([5, 20, 14, 32, 22, 38])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# With .fit(), you calculate the optimal values of the weights ùëè‚ÇÄ and ùëè‚ÇÅ\nmodel = LinearRegression().fit(x,y)\nmodel",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression()",
            "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# obtain the coefficient of determination, ùëÖ¬≤, with .score()\nr_sq = model.score(x, y)\nr_sq",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.7158756137479542"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# The attributes of model are .intercept_, which represents the coefficient ùëè‚ÇÄ, and .coef_, which represents ùëè‚ÇÅ\nmodel.intercept_",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "5.633333333333329"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model.coef_",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0.54])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# can use it for predictions with either existing or new data. To obtain the predicted response, use .predict()\ny_pred = model.predict(x)\ny_pred",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 8.33333333, 13.73333333, 19.13333333, 24.53333333, 29.93333333,\n       35.33333333])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_pred = model.intercept_ + model.coef_ * x \ny_pred # perdicted response",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 8.33333333],\n       [13.73333333],\n       [19.13333333],\n       [24.53333333],\n       [29.93333333],\n       [35.33333333]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "x_new = np.arange(5).reshape(-1,1)\nx_new",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0],\n       [1],\n       [2],\n       [3],\n       [4]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_new = model.predict(x_new)\ny_new",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([5.63333333, 6.17333333, 6.71333333, 7.25333333, 7.79333333])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Multiple Linear Regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\nx = [\n    [0,1], [5,1], [15,2], [25,5], [35,11], [45,15], [55,34], [60,35]\n]\ny = [4, 5, 20, 14, 32, 22, 38,43]\nx, y = np.array(x), np.array(y)\nx",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 0,  1],\n       [ 5,  1],\n       [15,  2],\n       [25,  5],\n       [35, 11],\n       [45, 15],\n       [55, 34],\n       [60, 35]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 4,  5, 20, 14, 32, 22, 38, 43])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model = LinearRegression().fit(x, y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r_sq = model.score(x, y)\nprint(f\"coefficient of determination: {r_sq}\")\nprint(f\"intercept: {model.intercept_}\")\nprint(f\"coefficients: {model.coef_}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "text": "coefficient of determination: 0.8615939258756775\nintercept: 5.52257927519819\ncoefficients: [0.44706965 0.25502548]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_pred = model.predict(x)\nprint(f\"predicted response:\\n{y_pred}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "text": "predicted response:\n[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n 38.78227633 41.27265006]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_pred = model.intercept_ + np.sum(model.coef_ * x, axis = 1)\nprint(f\"predicted response:\\n{y_pred}\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": "predicted response:\n[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n 38.78227633 41.27265006]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "x_new = np.arange(10).reshape(-1,2)\nx_new",
      "metadata": {
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[0, 1],\n       [2, 3],\n       [4, 5],\n       [6, 7],\n       [8, 9]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_new = model.predict(x_new)\ny_new",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 5.77760476,  7.18179502,  8.58598528,  9.99017554, 11.3943658 ])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Polynomial Regression ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# There‚Äôs only one extra step: you need to transform the array of inputs to include nonlinear terms such as ùë•¬≤.\nimport numpy as np \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x = np.array([5, 15, 25, 35, 45, 55]).reshape(-1,1)\ny = np.array([15, 11, 2, 8, 25, 32])\nx",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 5],\n       [15],\n       [25],\n       [35],\n       [45],\n       [55]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Âª∫Á´ã ùë•¬≤\ntransformer = PolynomialFeatures(degree=2, include_bias=False)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "transformer.fit(x)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PolynomialFeatures(include_bias=False)",
            "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PolynomialFeatures(include_bias=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "x_ = transformer.transform(x)\nx_",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[   5.,   25.],\n       [  15.,  225.],\n       [  25.,  625.],\n       [  35., 1225.],\n       [  45., 2025.],\n       [  55., 3025.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model = LinearRegression().fit(x_, y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r_sq = model.score(x_,y)\nprint(f'coefficient of determination: {r_sq}')\n\nprint(f'intercept: {model.intercept_}')\n\nprint(f'coefficients: {model.coef_}')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "text": "coefficient of determination: 0.8908516262498564\nintercept: 21.37232142857146\ncoefficients: [-1.32357143  0.02839286]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# method 2 \nx_ = PolynomialFeatures(degree=2, include_bias=True).fit_transform(x)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x_",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "execution_count": 10,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[1.000e+00, 5.000e+00, 2.500e+01],\n       [1.000e+00, 1.500e+01, 2.250e+02],\n       [1.000e+00, 2.500e+01, 6.250e+02],\n       [1.000e+00, 3.500e+01, 1.225e+03],\n       [1.000e+00, 4.500e+01, 2.025e+03],\n       [1.000e+00, 5.500e+01, 3.025e+03]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# the intercept is already included -> fit_intercept=False\nmodel = LinearRegression(fit_intercept=False).fit(x_,y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "r_sq = model.score(x_,y)\nprint(f'coefficient of determination: {r_sq}')\n\nprint(f'intercept: {model.intercept_}')\n\nprint(f'coefficients: {model.coef_}')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "text": "coefficient of determination: 0.8908516262498563\nintercept: 0.0\ncoefficients: [21.37232143 -1.32357143  0.02839286]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y_pred = model.predict(x_)\nprint(f'predicted response:\\n{y_pred}')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "text": "predicted response:\n[15.46428571  7.90714286  6.02857143  9.82857143 19.30714286 34.46428571]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "# Step 1: Import packages and classes\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Step 2a: Provide data\nx = [\n  [0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n]\ny = [4, 5, 20, 14, 32, 22, 38, 43]\nx, y = np.array(x), np.array(y)\n\n# Step 2b: Transform input data\nx_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n\n# Step 3: Create a model and fit it\nmodel = LinearRegression().fit(x_, y)\n\n# Step 4: Get results\nr_sq = model.score(x_, y)\nintercept, coefficients = model.intercept_, model.coef_\n\n# Step 5: Predict response\ny_pred = model.predict(x_)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# ùëì(ùë•‚ÇÅ, ùë•‚ÇÇ) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ùëè‚ÇÇùë•‚ÇÇ + ùëè‚ÇÉùë•‚ÇÅ¬≤ + ùëè‚ÇÑùë•‚ÇÅùë•‚ÇÇ + ùëè‚ÇÖùë•‚ÇÇ¬≤.\nprint(f\"coefficient of determination: {r_sq}\")\n# coefficient of determination: 0.9453701449127822\n\nprint(f\"intercept: {intercept}\")\n# intercept: 0.8430556452395876\n\nprint(f\"coefficients:\\n{coefficients}\")\n# coefficients:\n# [ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]\n\nprint(f\"predicted response:\\n{y_pred}\")\n# predicted response:\n# [ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636\n# 39.05631386 41.92339046]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "text": "coefficient of determination: 0.9453701449127819\nintercept: 0.8430556452396445\ncoefficients:\n[ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]\npredicted response:\n[ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636\n 39.05631386 41.92339046]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "# Advanced Linear Regression",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport statsmodels.api as sm",
      "metadata": {
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x = [\n    [0, 1],[5, 1],[15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]\n    ]\ny = [4, 5, 20, 14, 32, 22, 38, 43]\nx, y = np.array(x), np.array(y)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# add intercept ùëè‚ÇÄ\nx = sm.add_constant(x)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "x",
      "metadata": {
        "trusted": true
      },
      "execution_count": 25,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[ 1.,  0.,  1.],\n       [ 1.,  5.,  1.],\n       [ 1., 15.,  2.],\n       [ 1., 25.,  5.],\n       [ 1., 35., 11.],\n       [ 1., 45., 15.],\n       [ 1., 55., 34.],\n       [ 1., 60., 35.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "y",
      "metadata": {
        "trusted": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 4,  5, 20, 14, 32, 22, 38, 43])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "model = sm.OLS(y, x)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "result = model.fit()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "result.summary()",
      "metadata": {
        "trusted": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.11/site-packages/scipy/stats/_stats_py.py:1806: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=8\n  warnings.warn(\"kurtosistest only valid for n>=20 ... continuing \"\n",
          "output_type": "stream"
        },
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<class 'statsmodels.iolib.summary.Summary'>\n\"\"\"\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                      y   R-squared:                       0.862\nModel:                            OLS   Adj. R-squared:                  0.806\nMethod:                 Least Squares   F-statistic:                     15.56\nDate:                Mon, 06 Nov 2023   Prob (F-statistic):            0.00713\nTime:                        19:20:55   Log-Likelihood:                -24.316\nNo. Observations:                   8   AIC:                             54.63\nDf Residuals:                       5   BIC:                             54.87\nDf Model:                           2                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst          5.5226      4.431      1.246      0.268      -5.867      16.912\nx1             0.4471      0.285      1.567      0.178      -0.286       1.180\nx2             0.2550      0.453      0.563      0.598      -0.910       1.420\n==============================================================================\nOmnibus:                        0.561   Durbin-Watson:                   3.268\nProb(Omnibus):                  0.755   Jarque-Bera (JB):                0.534\nSkew:                           0.380   Prob(JB):                        0.766\nKurtosis:                       1.987   Cond. No.                         80.1\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\"\"\"",
            "text/html": "<table class=\"simpletable\">\n<caption>OLS Regression Results</caption>\n<tr>\n  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.862</td>\n</tr>\n<tr>\n  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.806</td>\n</tr>\n<tr>\n  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.56</td>\n</tr>\n<tr>\n  <th>Date:</th>             <td>Mon, 06 Nov 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00713</td>\n</tr>\n<tr>\n  <th>Time:</th>                 <td>19:20:55</td>     <th>  Log-Likelihood:    </th> <td> -24.316</td>\n</tr>\n<tr>\n  <th>No. Observations:</th>      <td>     8</td>      <th>  AIC:               </th> <td>   54.63</td>\n</tr>\n<tr>\n  <th>Df Residuals:</th>          <td>     5</td>      <th>  BIC:               </th> <td>   54.87</td>\n</tr>\n<tr>\n  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n</tr>\n<tr>\n  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n</tr>\n<tr>\n  <th>const</th> <td>    5.5226</td> <td>    4.431</td> <td>    1.246</td> <td> 0.268</td> <td>   -5.867</td> <td>   16.912</td>\n</tr>\n<tr>\n  <th>x1</th>    <td>    0.4471</td> <td>    0.285</td> <td>    1.567</td> <td> 0.178</td> <td>   -0.286</td> <td>    1.180</td>\n</tr>\n<tr>\n  <th>x2</th>    <td>    0.2550</td> <td>    0.453</td> <td>    0.563</td> <td> 0.598</td> <td>   -0.910</td> <td>    1.420</td>\n</tr>\n</table>\n<table class=\"simpletable\">\n<tr>\n  <th>Omnibus:</th>       <td> 0.561</td> <th>  Durbin-Watson:     </th> <td>   3.268</td>\n</tr>\n<tr>\n  <th>Prob(Omnibus):</th> <td> 0.755</td> <th>  Jarque-Bera (JB):  </th> <td>   0.534</td>\n</tr>\n<tr>\n  <th>Skew:</th>          <td> 0.380</td> <th>  Prob(JB):          </th> <td>   0.766</td>\n</tr>\n<tr>\n  <th>Kurtosis:</th>      <td> 1.987</td> <th>  Cond. No.          </th> <td>    80.1</td>\n</tr>\n</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.",
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.862   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.806   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     15.56   \\\\\n\\textbf{Date:}             & Mon, 06 Nov 2023 & \\textbf{  Prob (F-statistic):} &  0.00713    \\\\\n\\textbf{Time:}             &     19:20:55     & \\textbf{  Log-Likelihood:    } &   -24.316   \\\\\n\\textbf{No. Observations:} &           8      & \\textbf{  AIC:               } &     54.63   \\\\\n\\textbf{Df Residuals:}     &           5      & \\textbf{  BIC:               } &     54.87   \\\\\n\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       5.5226  &        4.431     &     1.246  &         0.268        &       -5.867    &       16.912     \\\\\n\\textbf{x1}    &       0.4471  &        0.285     &     1.567  &         0.178        &       -0.286    &        1.180     \\\\\n\\textbf{x2}    &       0.2550  &        0.453     &     0.563  &         0.598        &       -0.910    &        1.420     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       &  0.561 & \\textbf{  Durbin-Watson:     } &    3.268  \\\\\n\\textbf{Prob(Omnibus):} &  0.755 & \\textbf{  Jarque-Bera (JB):  } &    0.534  \\\\\n\\textbf{Skew:}          &  0.380 & \\textbf{  Prob(JB):          } &    0.766  \\\\\n\\textbf{Kurtosis:}      &  1.987 & \\textbf{  Cond. No.          } &     80.1  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "print(f\"coefficient of determination: {result.rsquared}\")\n# coefficient of determination: 0.8615939258756776 : ùëÖ¬≤\n\nprint(f\"adjusted coefficient of determination: {result.rsquared_adj}\")\n# adjusted coefficient of determination: 0.8062314962259487\n# adjusted ùëÖ¬≤‚Äîthat is, ùëÖ¬≤ corrected according to the number of input features.\nprint(f\"regression coefficients: {result.params}\")\n# regression coefficients: [5.52257928 0.44706965 0.25502548]\n# refers the array with ùëè‚ÇÄ, ùëè‚ÇÅ, and ùëè‚ÇÇ.",
      "metadata": {
        "trusted": true
      },
      "execution_count": 32,
      "outputs": [
        {
          "name": "stdout",
          "text": "coefficient of determination: 0.8615939258756776\nadjusted coefficient of determination: 0.8062314962259487\nregression coefficients: [5.52257928 0.44706965 0.25502548]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": ">>> print(f\"predicted response:\\n{result.fittedvalues}\")\n# predicted response:\n# [ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n#  38.78227633 41.27265006]\n\n>>> print(f\"predicted response:\\n{result.predict(x)}\")\n# predicted response:\n# [ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n#  38.78227633 41.27265006]",
      "metadata": {
        "trusted": true
      },
      "execution_count": 33,
      "outputs": [
        {
          "name": "stdout",
          "text": "predicted response:\n[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n 38.78227633 41.27265006]\npredicted response:\n[ 5.77760476  8.012953   12.73867497 17.9744479  23.97529728 29.4660957\n 38.78227633 41.27265006]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "x_new = sm.add_constant(np.arange(10).reshape((-1, 2)))\n# x_new\n# array([[1., 0., 1.],\n#        [1., 2., 3.],\n#        [1., 4., 5.],\n#        [1., 6., 7.],\n#        [1., 8., 9.]])\n\ny_new = result.predict(x_new)\ny_new\n# array([ 5.77760476,  7.18179502,  8.58598528,  9.99017554, 11.3943658 ])",
      "metadata": {
        "trusted": true
      },
      "execution_count": 35,
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 5.77760476,  7.18179502,  8.58598528,  9.99017554, 11.3943658 ])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### scikit-learn if you don‚Äôt need detailed results and want to use the approach consistent with other regression techniques\n### statsmodels if you need the advanced statistical parameters of a model",
      "metadata": {}
    }
  ]
}